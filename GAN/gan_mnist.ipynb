{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjianpingzhou0927\u001b[0m (\u001b[33msjtuzjp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ce9705ee4b43d28eb0e2df174c9e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667183729975174, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/zhoujianping/Research/ModelReproduce/GAN/wandb/run-20230307_105233-1p7gpje3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sjtuzjp/gan-mnist/runs/1p7gpje3' target=\"_blank\">jolly-valley-1</a></strong> to <a href='https://wandb.ai/sjtuzjp/gan-mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sjtuzjp/gan-mnist' target=\"_blank\">https://wandb.ai/sjtuzjp/gan-mnist</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sjtuzjp/gan-mnist/runs/1p7gpje3' target=\"_blank\">https://wandb.ai/sjtuzjp/gan-mnist/runs/1p7gpje3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sjtuzjp/gan-mnist/runs/1p7gpje3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc19de71580>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"gan-mnist\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": 0.0003,\n",
    "        \"epochs\": 100,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 设备配置\n",
    "torch.cuda.set_device(1) # 这句用来设置pytorch在哪块GPU上运行\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# 创建文件夹\n",
    "if not os.path.exists('./img'):\n",
    "    os.mkdir('./img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    out = 0.5 * (x + 1)\n",
    "    out = out.clamp(0, 1)  # Clamp函数可以将随机变化的数值限制在一个给定的区间[min, max]内：\n",
    "    out = out.view(-1, 1, 28, 28)  # view()函数作用是将一个多行的Tensor,拼接成一行\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "batch_size = 128\n",
    "num_epoch = 100\n",
    "z_dimension = 100\n",
    "# 图像预处理\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))  # (x-mean) / std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0684c4db60404b9288fa702cce7ae6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18d95ab2cdc40e2b72ca77ad4c52be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eeb6e91f3f14c16adb38ecc7d7a6540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8dd4dd0efb455689aed1b5ab0cd7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhoujianping/miniconda3/envs/torch3090/lib/python3.8/site-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# mnist dataset train数据集下载\n",
    "mnist = datasets.MNIST(root='./data/mnist',\n",
    "                       train=True,\n",
    "                       transform=img_transform,\n",
    "                       download=True)\n",
    "\n",
    "# data loader 数据载入\n",
    "dataloader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器  #####Discriminator######使用多层网络来作为判别器\n",
    "# 将图片28x28展开成784，然后通过多层感知器，中间经过斜率设置为0.2的LeakyReLU激活函数，\n",
    "# 最后接sigmoid激活函数得到一个0到1之间的概率进行二分类。\n",
    "class discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(784, 256),  # 输入特征数为784，输出为256\n",
    "            nn.LeakyReLU(0.2),  # 进行非线性映射\n",
    "            nn.Linear(256, 256),  # 进行一个线性映射\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # 也是一个激活函数，二分类问题中，\n",
    "            # sigmoid可以班实数映射到【0,1】，作为概率值，\n",
    "            # 多分类用softmax函数\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### 定义生成器 Generator #####\n",
    "# 输入一个100维的0～1之间的高斯分布，然后通过第一层线性变换将其映射到256维,\n",
    "# 然后通过LeakyReLU激活函数，接着进行一个线性变换，再经过一个LeakyReLU激活函数，\n",
    "# 然后经过线性变换将其变成784维，最后经过Tanh激活函数是希望生成的假的图片数据分布能够在-1～1之间。\n",
    "class generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(100, 256),  # 用线性变换将输入映射到256维\n",
    "            nn.ReLU(True),  # relu激活\n",
    "            nn.Linear(256, 256),  # 线性变换\n",
    "            nn.ReLU(True),  # relu激活\n",
    "            nn.Linear(256, 784),  # 线性变换\n",
    "            nn.Tanh()  # Tanh激活使得生成数据分布在【-1,1】之间，因为输入的真实数据的经过transforms之后也是这个分布\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gen(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建对象\n",
    "D = discriminator().to(device)\n",
    "G = generator().to(device)\n",
    "# if torch.cuda.is_available():\n",
    "#     D = D.cuda()\n",
    "#     G = G.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逐步打印训练过程的vector shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "torch.Size([128, 784])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128])\n",
      "tensor(0.6788, device='cuda:1', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([128])\n",
      "torch.Size([128, 100])\n",
      "torch.Size([128, 784])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "# 首先需要定义loss的度量方式  （二分类的交叉熵）\n",
    "# 其次定义优化函数,优化函数的学习率为0.0003\n",
    "criterion = nn.BCELoss()  # 是单目标二分类交叉熵函数\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)\n",
    "\n",
    "for i, (img, _) in enumerate(dataloader):\n",
    "    num_img = img.size(0)\n",
    "    print(num_img)  # 128\n",
    "    # view()函数作用是将一个多行的Tensor,拼接成一行\n",
    "    # 第一个参数是要拼接的tensor,第二个参数是-1\n",
    "    # =============================训练判别器==================\n",
    "    img = img.view(num_img, -1)  # 将图片展开为28*28=784\n",
    "    print(img.shape)    # (128,784)\n",
    "    real_img = Variable(img).cuda()  # 将tensor变成Variable放入计算图中\n",
    "    real_label = Variable(torch.ones(num_img)).cuda()  # 定义真实的图片label为1\n",
    "    fake_label = Variable(torch.zeros(num_img)).cuda()  # 定义假的图片的label为0\n",
    "\n",
    "    # ########判别器训练train#####################\n",
    "    # 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "\n",
    "    # 计算真实图片的损失\n",
    "    real_out = D(real_img)  # 将真实图片放入判别器中\n",
    "    print(real_out.shape)\n",
    "    real_out = real_out.squeeze()  # (128,1) -> (128,)\n",
    "    print(real_out.shape)   # 128\n",
    "\n",
    "    d_loss_real = criterion(real_out, real_label)  # 得到真实图片的loss\n",
    "    print(d_loss_real)\n",
    "    real_scores = real_out  # 得到真实图片的判别值，输出的值越接近1越好\n",
    "    print(real_scores.shape)    # 128\n",
    "\n",
    "    # 计算假的图片的损失\n",
    "    z = Variable(torch.randn(num_img, z_dimension)).cuda()  # 随机生成一些噪声\n",
    "    fake_img = G(\n",
    "        z).detach()  # 随机噪声放入生成网络中，生成一张假的图片。 # 避免梯度传到G，因为G不用更新, detach分离\n",
    "    fake_out = D(fake_img)  # 判别器判断假的图片\n",
    "    fake_out = fake_out.squeeze()  # (128,1) -> (128,)\n",
    "    d_loss_fake = criterion(fake_out, fake_label)  # 得到假的图片的loss\n",
    "    fake_scores = fake_out  # 得到假图片的判别值，对于判别器来说，假图片的损失越接近0越好\n",
    "\n",
    "    # 损失函数和优化\n",
    "    d_loss = d_loss_real + d_loss_fake  # 损失包括判真损失和判假损失\n",
    "    d_optimizer.zero_grad()  # 在反向传播之前，先将梯度归0\n",
    "    d_loss.backward()  # 将误差反向传播\n",
    "    d_optimizer.step()  # 更新参数\n",
    "\n",
    "\n",
    "    # ==================训练生成器============================\n",
    "    # ###############################生成网络的训练###############################\n",
    "    # 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "    # 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "    # 反向传播更新的参数是生成网络里面的参数，\n",
    "    # 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的\n",
    "    # 这样就达到了对抗的目的\n",
    "    # 计算假的图片的损失\n",
    "    z = Variable(torch.randn(num_img, z_dimension)).cuda()  # 得到随机噪声\n",
    "    print(z.shape)  # (128,100)\n",
    "    fake_img = G(z)  # 随机噪声输入到生成器中，得到一副假的图片\n",
    "    print(fake_img.shape)   # (128,784)\n",
    "    output = D(fake_img)  # 经过判别器得到的结果\n",
    "    print(output.shape) # (128,1)\n",
    "    output = output.squeeze()\n",
    "    g_loss = criterion(output, real_label)  # 得到的假的图片与真实的图片的label的loss\n",
    "    # bp and optimize\n",
    "    g_optimizer.zero_grad()  # 梯度归0\n",
    "    g_loss.backward()  # 进行反向传播\n",
    "    g_optimizer.step()  # .step()一般用在反向传播后面,用于更新生成网络的参数\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/100],d_loss:0.188616,g_loss:3.179043 D real: 0.956892,D fake: 0.130629\n",
      "Epoch[0/100],d_loss:0.024438,g_loss:4.703603 D real: 0.997647,D fake: 0.021758\n",
      "Epoch[0/100],d_loss:0.210749,g_loss:5.839513 D real: 0.970132,D fake: 0.132535\n",
      "Epoch[0/100],d_loss:0.088411,g_loss:5.436432 D real: 0.980465,D fake: 0.061762\n",
      "Epoch[1/100],d_loss:0.031820,g_loss:5.491758 D real: 0.981815,D fake: 0.010042\n",
      "Epoch[1/100],d_loss:0.017488,g_loss:6.660955 D real: 0.998567,D fake: 0.015685\n",
      "Epoch[1/100],d_loss:0.348130,g_loss:4.930775 D real: 0.887380,D fake: 0.111554\n",
      "Epoch[1/100],d_loss:0.155825,g_loss:5.267170 D real: 0.939481,D fake: 0.044494\n",
      "Epoch[2/100],d_loss:1.146036,g_loss:4.903194 D real: 0.868736,D fake: 0.457917\n",
      "Epoch[2/100],d_loss:0.090659,g_loss:5.787194 D real: 0.970833,D fake: 0.044559\n",
      "Epoch[2/100],d_loss:0.308463,g_loss:4.019037 D real: 0.913866,D fake: 0.132509\n",
      "Epoch[2/100],d_loss:0.198864,g_loss:3.539353 D real: 0.951901,D fake: 0.114046\n",
      "Epoch[3/100],d_loss:0.850701,g_loss:2.237185 D real: 0.764944,D fake: 0.269778\n",
      "Epoch[3/100],d_loss:2.114118,g_loss:3.753489 D real: 0.617463,D fake: 0.443350\n",
      "Epoch[3/100],d_loss:0.812887,g_loss:3.245131 D real: 0.778863,D fake: 0.238920\n",
      "Epoch[3/100],d_loss:0.312765,g_loss:3.200336 D real: 0.881180,D fake: 0.106291\n",
      "Epoch[4/100],d_loss:0.550801,g_loss:2.380232 D real: 0.894947,D fake: 0.261514\n",
      "Epoch[4/100],d_loss:0.360095,g_loss:2.974147 D real: 0.905951,D fake: 0.179674\n",
      "Epoch[4/100],d_loss:0.998326,g_loss:3.268472 D real: 0.810966,D fake: 0.313976\n",
      "Epoch[4/100],d_loss:0.560709,g_loss:3.346161 D real: 0.813365,D fake: 0.169429\n",
      "Epoch[5/100],d_loss:0.384906,g_loss:2.808293 D real: 0.927534,D fake: 0.231229\n",
      "Epoch[5/100],d_loss:1.290452,g_loss:2.047962 D real: 0.666808,D fake: 0.375291\n",
      "Epoch[5/100],d_loss:0.806948,g_loss:2.285038 D real: 0.721073,D fake: 0.197308\n",
      "Epoch[5/100],d_loss:0.819952,g_loss:1.684562 D real: 0.757102,D fake: 0.276460\n",
      "Epoch[6/100],d_loss:0.337175,g_loss:3.085989 D real: 0.848612,D fake: 0.080131\n",
      "Epoch[6/100],d_loss:0.194853,g_loss:2.890654 D real: 0.935845,D fake: 0.092364\n",
      "Epoch[6/100],d_loss:0.502431,g_loss:2.756082 D real: 0.817889,D fake: 0.110482\n",
      "Epoch[6/100],d_loss:0.832040,g_loss:2.893133 D real: 0.709689,D fake: 0.149996\n",
      "Epoch[7/100],d_loss:0.395384,g_loss:4.987159 D real: 0.892583,D fake: 0.145671\n",
      "Epoch[7/100],d_loss:0.705105,g_loss:5.271224 D real: 0.805719,D fake: 0.150457\n",
      "Epoch[7/100],d_loss:0.386015,g_loss:2.850847 D real: 0.903702,D fake: 0.215152\n",
      "Epoch[7/100],d_loss:0.836576,g_loss:2.671158 D real: 0.848526,D fake: 0.339084\n",
      "Epoch[8/100],d_loss:0.820199,g_loss:2.442063 D real: 0.813333,D fake: 0.309385\n",
      "Epoch[8/100],d_loss:0.274120,g_loss:5.469817 D real: 0.948389,D fake: 0.130189\n",
      "Epoch[8/100],d_loss:0.232434,g_loss:3.344020 D real: 0.960751,D fake: 0.155714\n",
      "Epoch[8/100],d_loss:0.301860,g_loss:3.226351 D real: 0.882182,D fake: 0.114259\n",
      "Epoch[9/100],d_loss:1.554494,g_loss:1.327073 D real: 0.738467,D fake: 0.515265\n",
      "Epoch[9/100],d_loss:1.535890,g_loss:1.504939 D real: 0.583621,D fake: 0.366664\n",
      "Epoch[9/100],d_loss:1.077652,g_loss:1.455653 D real: 0.705272,D fake: 0.330213\n",
      "Epoch[9/100],d_loss:0.752898,g_loss:2.189257 D real: 0.710435,D fake: 0.220870\n",
      "Epoch[10/100],d_loss:0.342811,g_loss:2.753280 D real: 0.869044,D fake: 0.131384\n",
      "Epoch[10/100],d_loss:0.678115,g_loss:1.734680 D real: 0.832246,D fake: 0.324223\n",
      "Epoch[10/100],d_loss:0.224177,g_loss:3.797968 D real: 0.914132,D fake: 0.082465\n",
      "Epoch[10/100],d_loss:0.478067,g_loss:2.315442 D real: 0.827926,D fake: 0.144262\n",
      "Epoch[11/100],d_loss:0.875802,g_loss:2.027733 D real: 0.772299,D fake: 0.317236\n",
      "Epoch[11/100],d_loss:0.406554,g_loss:3.774567 D real: 0.859217,D fake: 0.096801\n",
      "Epoch[11/100],d_loss:0.477219,g_loss:2.826577 D real: 0.817973,D fake: 0.083411\n",
      "Epoch[11/100],d_loss:0.328311,g_loss:3.340049 D real: 0.924292,D fake: 0.158896\n",
      "Epoch[12/100],d_loss:0.739248,g_loss:3.287633 D real: 0.798331,D fake: 0.142002\n",
      "Epoch[12/100],d_loss:0.285465,g_loss:5.209669 D real: 0.888818,D fake: 0.055122\n",
      "Epoch[12/100],d_loss:0.234829,g_loss:4.652156 D real: 0.928215,D fake: 0.033341\n",
      "Epoch[12/100],d_loss:0.218347,g_loss:3.141756 D real: 0.932951,D fake: 0.097194\n",
      "Epoch[13/100],d_loss:0.400402,g_loss:4.417172 D real: 0.875217,D fake: 0.116269\n",
      "Epoch[13/100],d_loss:0.527668,g_loss:5.877638 D real: 0.838893,D fake: 0.083217\n",
      "Epoch[13/100],d_loss:0.303505,g_loss:3.875764 D real: 0.901433,D fake: 0.105299\n",
      "Epoch[13/100],d_loss:0.429810,g_loss:5.185886 D real: 0.833934,D fake: 0.061452\n",
      "Epoch[14/100],d_loss:0.365621,g_loss:3.947367 D real: 0.869624,D fake: 0.096845\n",
      "Epoch[14/100],d_loss:0.657756,g_loss:2.331250 D real: 0.757584,D fake: 0.087698\n",
      "Epoch[14/100],d_loss:0.564772,g_loss:4.211997 D real: 0.846607,D fake: 0.113256\n",
      "Epoch[14/100],d_loss:0.428007,g_loss:3.455176 D real: 0.896983,D fake: 0.191420\n",
      "Epoch[15/100],d_loss:0.448491,g_loss:3.541151 D real: 0.865902,D fake: 0.107524\n",
      "Epoch[15/100],d_loss:0.214000,g_loss:4.282951 D real: 0.912959,D fake: 0.041331\n",
      "Epoch[15/100],d_loss:0.284162,g_loss:4.695425 D real: 0.910741,D fake: 0.067209\n",
      "Epoch[15/100],d_loss:0.294821,g_loss:3.209691 D real: 0.932155,D fake: 0.119576\n",
      "Epoch[16/100],d_loss:0.346756,g_loss:3.475764 D real: 0.908672,D fake: 0.114125\n",
      "Epoch[16/100],d_loss:0.138050,g_loss:5.036630 D real: 0.966270,D fake: 0.040662\n",
      "Epoch[16/100],d_loss:0.432192,g_loss:3.563515 D real: 0.917325,D fake: 0.208235\n",
      "Epoch[16/100],d_loss:0.277402,g_loss:3.135029 D real: 0.938138,D fake: 0.111962\n",
      "Epoch[17/100],d_loss:0.424709,g_loss:2.863226 D real: 0.866570,D fake: 0.123596\n",
      "Epoch[17/100],d_loss:0.364247,g_loss:3.546457 D real: 0.866086,D fake: 0.068945\n",
      "Epoch[17/100],d_loss:0.343091,g_loss:4.070259 D real: 0.889735,D fake: 0.084955\n",
      "Epoch[17/100],d_loss:0.527910,g_loss:3.957449 D real: 0.859580,D fake: 0.117234\n",
      "Epoch[18/100],d_loss:0.345514,g_loss:4.223346 D real: 0.922065,D fake: 0.115412\n",
      "Epoch[18/100],d_loss:0.382299,g_loss:2.560609 D real: 0.905204,D fake: 0.147778\n",
      "Epoch[18/100],d_loss:0.386632,g_loss:4.149938 D real: 0.875516,D fake: 0.082818\n",
      "Epoch[18/100],d_loss:0.259608,g_loss:2.931990 D real: 0.924421,D fake: 0.117669\n",
      "Epoch[19/100],d_loss:0.326995,g_loss:3.469807 D real: 0.902990,D fake: 0.101139\n",
      "Epoch[19/100],d_loss:0.541097,g_loss:2.830165 D real: 0.916209,D fake: 0.234422\n",
      "Epoch[19/100],d_loss:0.795250,g_loss:2.196161 D real: 0.784390,D fake: 0.187497\n",
      "Epoch[19/100],d_loss:0.592300,g_loss:2.928500 D real: 0.841842,D fake: 0.199794\n",
      "Epoch[20/100],d_loss:0.584837,g_loss:2.082233 D real: 0.833319,D fake: 0.176444\n",
      "Epoch[20/100],d_loss:0.652380,g_loss:2.976725 D real: 0.844835,D fake: 0.241304\n",
      "Epoch[20/100],d_loss:0.930880,g_loss:3.609855 D real: 0.834892,D fake: 0.354524\n",
      "Epoch[20/100],d_loss:0.226463,g_loss:3.258148 D real: 0.918121,D fake: 0.080702\n",
      "Epoch[21/100],d_loss:0.463348,g_loss:3.751736 D real: 0.859029,D fake: 0.134685\n",
      "Epoch[21/100],d_loss:0.353099,g_loss:3.561856 D real: 0.856865,D fake: 0.079975\n",
      "Epoch[21/100],d_loss:0.612514,g_loss:2.222561 D real: 0.820173,D fake: 0.178550\n",
      "Epoch[21/100],d_loss:0.341882,g_loss:3.480772 D real: 0.886015,D fake: 0.110053\n",
      "Epoch[22/100],d_loss:0.268762,g_loss:3.866854 D real: 0.894458,D fake: 0.064125\n",
      "Epoch[22/100],d_loss:0.368821,g_loss:2.736753 D real: 0.902802,D fake: 0.149157\n",
      "Epoch[22/100],d_loss:0.345105,g_loss:2.575337 D real: 0.881583,D fake: 0.118276\n",
      "Epoch[22/100],d_loss:0.434633,g_loss:2.629394 D real: 0.870696,D fake: 0.140675\n",
      "Epoch[23/100],d_loss:0.664335,g_loss:3.639862 D real: 0.880225,D fake: 0.262927\n",
      "Epoch[23/100],d_loss:0.326457,g_loss:4.925561 D real: 0.904719,D fake: 0.105753\n",
      "Epoch[23/100],d_loss:0.433184,g_loss:3.787004 D real: 0.897808,D fake: 0.158550\n",
      "Epoch[23/100],d_loss:0.404357,g_loss:3.161900 D real: 0.874324,D fake: 0.128049\n",
      "Epoch[24/100],d_loss:0.228845,g_loss:5.087586 D real: 0.918447,D fake: 0.069593\n",
      "Epoch[24/100],d_loss:0.778516,g_loss:5.049974 D real: 0.841438,D fake: 0.203216\n",
      "Epoch[24/100],d_loss:0.608931,g_loss:3.445286 D real: 0.899760,D fake: 0.218123\n",
      "Epoch[24/100],d_loss:0.324814,g_loss:4.350849 D real: 0.887243,D fake: 0.108945\n",
      "Epoch[25/100],d_loss:0.578813,g_loss:3.482655 D real: 0.817953,D fake: 0.199106\n",
      "Epoch[25/100],d_loss:0.792202,g_loss:2.573044 D real: 0.762362,D fake: 0.195907\n",
      "Epoch[25/100],d_loss:0.349027,g_loss:4.066035 D real: 0.856911,D fake: 0.086904\n",
      "Epoch[25/100],d_loss:0.481434,g_loss:3.623456 D real: 0.866054,D fake: 0.175147\n",
      "Epoch[26/100],d_loss:0.315083,g_loss:4.090677 D real: 0.877676,D fake: 0.068502\n",
      "Epoch[26/100],d_loss:0.263973,g_loss:3.118671 D real: 0.926240,D fake: 0.123496\n",
      "Epoch[26/100],d_loss:0.706766,g_loss:3.015806 D real: 0.741741,D fake: 0.070691\n",
      "Epoch[26/100],d_loss:0.504232,g_loss:2.524426 D real: 0.894787,D fake: 0.182933\n",
      "Epoch[27/100],d_loss:0.305013,g_loss:4.184949 D real: 0.887750,D fake: 0.096401\n",
      "Epoch[27/100],d_loss:0.275195,g_loss:3.016696 D real: 0.926137,D fake: 0.103532\n",
      "Epoch[27/100],d_loss:0.481309,g_loss:3.256855 D real: 0.894298,D fake: 0.158255\n",
      "Epoch[27/100],d_loss:0.351840,g_loss:3.613153 D real: 0.869678,D fake: 0.087244\n",
      "Epoch[28/100],d_loss:0.258960,g_loss:5.299734 D real: 0.893817,D fake: 0.035014\n",
      "Epoch[28/100],d_loss:0.247027,g_loss:4.367083 D real: 0.905778,D fake: 0.071722\n",
      "Epoch[28/100],d_loss:0.300164,g_loss:4.474032 D real: 0.934929,D fake: 0.136125\n",
      "Epoch[28/100],d_loss:0.425208,g_loss:4.031485 D real: 0.872265,D fake: 0.115583\n",
      "Epoch[29/100],d_loss:0.368269,g_loss:2.821992 D real: 0.890941,D fake: 0.113669\n",
      "Epoch[29/100],d_loss:0.270792,g_loss:3.324955 D real: 0.896825,D fake: 0.096735\n",
      "Epoch[29/100],d_loss:0.328156,g_loss:3.010589 D real: 0.882003,D fake: 0.103645\n",
      "Epoch[29/100],d_loss:0.390462,g_loss:3.416428 D real: 0.906424,D fake: 0.166069\n",
      "Epoch[30/100],d_loss:0.485442,g_loss:2.763899 D real: 0.877016,D fake: 0.196549\n",
      "Epoch[30/100],d_loss:0.556779,g_loss:3.009452 D real: 0.879553,D fake: 0.204472\n",
      "Epoch[30/100],d_loss:0.399295,g_loss:3.810167 D real: 0.939198,D fake: 0.171605\n",
      "Epoch[30/100],d_loss:0.421184,g_loss:3.104295 D real: 0.883952,D fake: 0.146752\n",
      "Epoch[31/100],d_loss:0.396479,g_loss:4.582003 D real: 0.879181,D fake: 0.077291\n",
      "Epoch[31/100],d_loss:0.338108,g_loss:4.531511 D real: 0.883289,D fake: 0.077960\n",
      "Epoch[31/100],d_loss:0.486360,g_loss:3.825994 D real: 0.958737,D fake: 0.280269\n",
      "Epoch[31/100],d_loss:0.292279,g_loss:3.388728 D real: 0.934987,D fake: 0.115423\n",
      "Epoch[32/100],d_loss:0.443266,g_loss:4.415982 D real: 0.833000,D fake: 0.092636\n",
      "Epoch[32/100],d_loss:0.429243,g_loss:3.883238 D real: 0.851230,D fake: 0.071287\n",
      "Epoch[32/100],d_loss:0.574970,g_loss:2.776254 D real: 0.873589,D fake: 0.232696\n",
      "Epoch[32/100],d_loss:0.428275,g_loss:3.641802 D real: 0.870290,D fake: 0.113687\n",
      "Epoch[33/100],d_loss:0.426988,g_loss:2.816064 D real: 0.917076,D fake: 0.198442\n",
      "Epoch[33/100],d_loss:0.586728,g_loss:3.319420 D real: 0.898099,D fake: 0.226118\n",
      "Epoch[33/100],d_loss:0.659305,g_loss:3.297937 D real: 0.867404,D fake: 0.224716\n",
      "Epoch[33/100],d_loss:0.524954,g_loss:4.273847 D real: 0.856109,D fake: 0.151206\n",
      "Epoch[34/100],d_loss:0.238793,g_loss:3.925302 D real: 0.910479,D fake: 0.073561\n",
      "Epoch[34/100],d_loss:0.404197,g_loss:3.266878 D real: 0.890269,D fake: 0.152138\n",
      "Epoch[34/100],d_loss:0.605471,g_loss:3.544830 D real: 0.907141,D fake: 0.271681\n",
      "Epoch[34/100],d_loss:0.448353,g_loss:3.087204 D real: 0.916083,D fake: 0.199529\n",
      "Epoch[35/100],d_loss:0.633559,g_loss:4.429092 D real: 0.839451,D fake: 0.169551\n",
      "Epoch[35/100],d_loss:0.441596,g_loss:2.649794 D real: 0.889687,D fake: 0.158183\n",
      "Epoch[35/100],d_loss:0.353279,g_loss:2.658906 D real: 0.899708,D fake: 0.123347\n",
      "Epoch[35/100],d_loss:0.338237,g_loss:4.122417 D real: 0.959340,D fake: 0.193260\n",
      "Epoch[36/100],d_loss:0.500856,g_loss:2.563979 D real: 0.862704,D fake: 0.136823\n",
      "Epoch[36/100],d_loss:0.568932,g_loss:1.771085 D real: 0.815828,D fake: 0.165230\n",
      "Epoch[36/100],d_loss:0.506794,g_loss:2.229357 D real: 0.873481,D fake: 0.168344\n",
      "Epoch[36/100],d_loss:0.301855,g_loss:3.329220 D real: 0.899894,D fake: 0.109060\n",
      "Epoch[37/100],d_loss:0.299536,g_loss:3.724655 D real: 0.911659,D fake: 0.112235\n",
      "Epoch[37/100],d_loss:0.691265,g_loss:3.009368 D real: 0.757504,D fake: 0.109215\n",
      "Epoch[37/100],d_loss:0.492465,g_loss:3.191844 D real: 0.835492,D fake: 0.104196\n",
      "Epoch[37/100],d_loss:0.380188,g_loss:3.114229 D real: 0.919044,D fake: 0.182755\n",
      "Epoch[38/100],d_loss:0.351877,g_loss:4.297836 D real: 0.910568,D fake: 0.137202\n",
      "Epoch[38/100],d_loss:0.632276,g_loss:3.560922 D real: 0.815340,D fake: 0.130472\n",
      "Epoch[38/100],d_loss:0.390917,g_loss:3.663896 D real: 0.915493,D fake: 0.173947\n",
      "Epoch[38/100],d_loss:0.497761,g_loss:2.870780 D real: 0.847446,D fake: 0.137648\n",
      "Epoch[39/100],d_loss:0.525231,g_loss:4.068051 D real: 0.838090,D fake: 0.054922\n",
      "Epoch[39/100],d_loss:0.415234,g_loss:3.310558 D real: 0.905663,D fake: 0.193192\n",
      "Epoch[39/100],d_loss:0.594020,g_loss:3.214595 D real: 0.789566,D fake: 0.095592\n",
      "Epoch[39/100],d_loss:0.306771,g_loss:3.806563 D real: 0.926563,D fake: 0.138916\n",
      "Epoch[40/100],d_loss:0.567394,g_loss:3.292264 D real: 0.811546,D fake: 0.134281\n",
      "Epoch[40/100],d_loss:0.339077,g_loss:4.239223 D real: 0.893757,D fake: 0.117965\n",
      "Epoch[40/100],d_loss:0.498655,g_loss:2.841327 D real: 0.920073,D fake: 0.224170\n",
      "Epoch[40/100],d_loss:0.418229,g_loss:3.181262 D real: 0.853296,D fake: 0.099369\n",
      "Epoch[41/100],d_loss:0.519348,g_loss:3.341940 D real: 0.919715,D fake: 0.257911\n",
      "Epoch[41/100],d_loss:0.318995,g_loss:3.183335 D real: 0.876237,D fake: 0.072113\n",
      "Epoch[41/100],d_loss:0.768785,g_loss:2.440465 D real: 0.811335,D fake: 0.188913\n",
      "Epoch[41/100],d_loss:0.488027,g_loss:3.459171 D real: 0.844011,D fake: 0.146668\n",
      "Epoch[42/100],d_loss:0.419861,g_loss:2.624242 D real: 0.909265,D fake: 0.218372\n",
      "Epoch[42/100],d_loss:0.514882,g_loss:3.055707 D real: 0.870300,D fake: 0.185627\n",
      "Epoch[42/100],d_loss:0.402955,g_loss:3.247584 D real: 0.847335,D fake: 0.096548\n",
      "Epoch[42/100],d_loss:0.683218,g_loss:2.923522 D real: 0.812541,D fake: 0.173218\n",
      "Epoch[43/100],d_loss:0.362769,g_loss:3.354845 D real: 0.866037,D fake: 0.122478\n",
      "Epoch[43/100],d_loss:0.373799,g_loss:3.114147 D real: 0.892463,D fake: 0.132133\n",
      "Epoch[43/100],d_loss:0.521172,g_loss:3.062418 D real: 0.855187,D fake: 0.210738\n",
      "Epoch[43/100],d_loss:0.531464,g_loss:2.652288 D real: 0.863799,D fake: 0.219900\n",
      "Epoch[44/100],d_loss:0.488664,g_loss:2.676521 D real: 0.789175,D fake: 0.097622\n",
      "Epoch[44/100],d_loss:0.638187,g_loss:2.389399 D real: 0.850003,D fake: 0.220995\n",
      "Epoch[44/100],d_loss:0.744176,g_loss:2.487536 D real: 0.752300,D fake: 0.111708\n",
      "Epoch[44/100],d_loss:0.563589,g_loss:3.343603 D real: 0.838710,D fake: 0.177244\n",
      "Epoch[45/100],d_loss:0.484721,g_loss:2.884394 D real: 0.853350,D fake: 0.169431\n",
      "Epoch[45/100],d_loss:0.504183,g_loss:2.770830 D real: 0.814426,D fake: 0.115598\n",
      "Epoch[45/100],d_loss:0.756306,g_loss:2.643176 D real: 0.737095,D fake: 0.119625\n",
      "Epoch[45/100],d_loss:0.559430,g_loss:2.768624 D real: 0.841834,D fake: 0.171886\n",
      "Epoch[46/100],d_loss:0.493575,g_loss:2.803788 D real: 0.880872,D fake: 0.202526\n",
      "Epoch[46/100],d_loss:0.429770,g_loss:3.674130 D real: 0.820465,D fake: 0.082804\n",
      "Epoch[46/100],d_loss:0.519849,g_loss:3.004206 D real: 0.798919,D fake: 0.120537\n",
      "Epoch[46/100],d_loss:0.448401,g_loss:2.969863 D real: 0.849802,D fake: 0.147119\n",
      "Epoch[47/100],d_loss:0.435501,g_loss:3.295776 D real: 0.841586,D fake: 0.116951\n",
      "Epoch[47/100],d_loss:0.564589,g_loss:2.632646 D real: 0.868242,D fake: 0.205366\n",
      "Epoch[47/100],d_loss:0.345448,g_loss:3.859703 D real: 0.878567,D fake: 0.115371\n",
      "Epoch[47/100],d_loss:0.385315,g_loss:3.434382 D real: 0.904448,D fake: 0.152552\n",
      "Epoch[48/100],d_loss:0.445045,g_loss:2.727096 D real: 0.885921,D fake: 0.156272\n",
      "Epoch[48/100],d_loss:0.539063,g_loss:3.337076 D real: 0.828855,D fake: 0.138842\n",
      "Epoch[48/100],d_loss:0.555228,g_loss:3.865454 D real: 0.824393,D fake: 0.124183\n",
      "Epoch[48/100],d_loss:0.507685,g_loss:3.645346 D real: 0.861332,D fake: 0.164172\n",
      "Epoch[49/100],d_loss:0.573020,g_loss:3.382495 D real: 0.820117,D fake: 0.143473\n",
      "Epoch[49/100],d_loss:0.482194,g_loss:3.574771 D real: 0.867925,D fake: 0.137483\n",
      "Epoch[49/100],d_loss:0.433813,g_loss:3.242708 D real: 0.915455,D fake: 0.186624\n",
      "Epoch[49/100],d_loss:0.608309,g_loss:3.322907 D real: 0.847923,D fake: 0.200014\n",
      "Epoch[50/100],d_loss:0.476731,g_loss:2.939420 D real: 0.909093,D fake: 0.218036\n",
      "Epoch[50/100],d_loss:0.445604,g_loss:2.658446 D real: 0.792442,D fake: 0.075211\n",
      "Epoch[50/100],d_loss:0.441423,g_loss:2.685365 D real: 0.903529,D fake: 0.181740\n",
      "Epoch[50/100],d_loss:0.511564,g_loss:2.689007 D real: 0.865664,D fake: 0.195460\n",
      "Epoch[51/100],d_loss:0.405235,g_loss:2.659757 D real: 0.888392,D fake: 0.168096\n",
      "Epoch[51/100],d_loss:0.370543,g_loss:2.947301 D real: 0.882331,D fake: 0.123145\n",
      "Epoch[51/100],d_loss:0.519811,g_loss:2.374275 D real: 0.850494,D fake: 0.192397\n",
      "Epoch[51/100],d_loss:0.411898,g_loss:2.627795 D real: 0.889756,D fake: 0.159834\n",
      "Epoch[52/100],d_loss:0.443247,g_loss:2.855213 D real: 0.872231,D fake: 0.167886\n",
      "Epoch[52/100],d_loss:0.613099,g_loss:2.585229 D real: 0.785591,D fake: 0.158625\n",
      "Epoch[52/100],d_loss:0.529726,g_loss:2.669921 D real: 0.853601,D fake: 0.203713\n",
      "Epoch[52/100],d_loss:0.492183,g_loss:3.457131 D real: 0.818326,D fake: 0.100221\n",
      "Epoch[53/100],d_loss:0.453062,g_loss:3.092785 D real: 0.893425,D fake: 0.186479\n",
      "Epoch[53/100],d_loss:0.561128,g_loss:2.516303 D real: 0.864767,D fake: 0.232413\n",
      "Epoch[53/100],d_loss:0.596425,g_loss:2.924667 D real: 0.861475,D fake: 0.236714\n",
      "Epoch[53/100],d_loss:0.333024,g_loss:2.873882 D real: 0.942824,D fake: 0.181756\n",
      "Epoch[54/100],d_loss:0.563785,g_loss:2.848803 D real: 0.813223,D fake: 0.160602\n",
      "Epoch[54/100],d_loss:0.521004,g_loss:2.608119 D real: 0.805742,D fake: 0.123043\n",
      "Epoch[54/100],d_loss:0.672455,g_loss:2.613105 D real: 0.797803,D fake: 0.196080\n",
      "Epoch[54/100],d_loss:0.660499,g_loss:2.463188 D real: 0.825164,D fake: 0.249750\n",
      "Epoch[55/100],d_loss:0.602099,g_loss:2.450588 D real: 0.793077,D fake: 0.174957\n",
      "Epoch[55/100],d_loss:0.448305,g_loss:3.025768 D real: 0.859277,D fake: 0.148727\n",
      "Epoch[55/100],d_loss:0.707039,g_loss:2.043844 D real: 0.845317,D fake: 0.293942\n",
      "Epoch[55/100],d_loss:0.726885,g_loss:1.958011 D real: 0.772287,D fake: 0.197739\n",
      "Epoch[56/100],d_loss:0.569264,g_loss:2.524713 D real: 0.780852,D fake: 0.118256\n",
      "Epoch[56/100],d_loss:0.529048,g_loss:2.739223 D real: 0.844598,D fake: 0.164751\n",
      "Epoch[56/100],d_loss:0.641450,g_loss:2.096326 D real: 0.767934,D fake: 0.167434\n",
      "Epoch[56/100],d_loss:0.600523,g_loss:2.872131 D real: 0.792280,D fake: 0.161187\n",
      "Epoch[57/100],d_loss:0.521226,g_loss:2.566694 D real: 0.810565,D fake: 0.139529\n",
      "Epoch[57/100],d_loss:0.574178,g_loss:2.948152 D real: 0.814349,D fake: 0.168261\n",
      "Epoch[57/100],d_loss:0.562148,g_loss:2.496405 D real: 0.895624,D fake: 0.253033\n",
      "Epoch[57/100],d_loss:0.978957,g_loss:2.816586 D real: 0.666814,D fake: 0.164335\n",
      "Epoch[58/100],d_loss:0.494558,g_loss:2.325623 D real: 0.835983,D fake: 0.176547\n",
      "Epoch[58/100],d_loss:0.496410,g_loss:2.715601 D real: 0.833123,D fake: 0.155847\n",
      "Epoch[58/100],d_loss:0.505930,g_loss:2.778333 D real: 0.851984,D fake: 0.197050\n",
      "Epoch[58/100],d_loss:0.737095,g_loss:2.165056 D real: 0.801043,D fake: 0.277012\n",
      "Epoch[59/100],d_loss:0.537891,g_loss:2.787868 D real: 0.796828,D fake: 0.145916\n",
      "Epoch[59/100],d_loss:0.640661,g_loss:1.816698 D real: 0.817565,D fake: 0.220896\n",
      "Epoch[59/100],d_loss:0.496707,g_loss:2.252242 D real: 0.825316,D fake: 0.131018\n",
      "Epoch[59/100],d_loss:0.535431,g_loss:2.822480 D real: 0.819158,D fake: 0.186389\n",
      "Epoch[60/100],d_loss:0.688646,g_loss:2.441029 D real: 0.885796,D fake: 0.322516\n",
      "Epoch[60/100],d_loss:0.646011,g_loss:2.108567 D real: 0.809145,D fake: 0.214819\n",
      "Epoch[60/100],d_loss:0.592579,g_loss:2.858252 D real: 0.879188,D fake: 0.250018\n",
      "Epoch[60/100],d_loss:0.610343,g_loss:2.473286 D real: 0.802719,D fake: 0.185530\n",
      "Epoch[61/100],d_loss:0.440740,g_loss:2.055510 D real: 0.843986,D fake: 0.161826\n",
      "Epoch[61/100],d_loss:0.601910,g_loss:2.210230 D real: 0.902357,D fake: 0.298668\n",
      "Epoch[61/100],d_loss:0.555017,g_loss:2.673648 D real: 0.812066,D fake: 0.166307\n",
      "Epoch[61/100],d_loss:0.535182,g_loss:2.954761 D real: 0.780486,D fake: 0.094472\n",
      "Epoch[62/100],d_loss:0.436986,g_loss:2.674566 D real: 0.867658,D fake: 0.181709\n",
      "Epoch[62/100],d_loss:0.647212,g_loss:2.419919 D real: 0.813106,D fake: 0.228684\n",
      "Epoch[62/100],d_loss:0.483075,g_loss:3.707104 D real: 0.813679,D fake: 0.120570\n",
      "Epoch[62/100],d_loss:0.583726,g_loss:3.020505 D real: 0.770035,D fake: 0.134450\n",
      "Epoch[63/100],d_loss:0.512603,g_loss:3.453753 D real: 0.799448,D fake: 0.122040\n",
      "Epoch[63/100],d_loss:0.619184,g_loss:2.016555 D real: 0.778787,D fake: 0.154210\n",
      "Epoch[63/100],d_loss:0.610307,g_loss:2.518292 D real: 0.858802,D fake: 0.241974\n",
      "Epoch[63/100],d_loss:0.627750,g_loss:2.212315 D real: 0.827869,D fake: 0.239190\n",
      "Epoch[64/100],d_loss:0.589515,g_loss:2.701945 D real: 0.804691,D fake: 0.173466\n",
      "Epoch[64/100],d_loss:0.739240,g_loss:2.642042 D real: 0.814946,D fake: 0.266989\n",
      "Epoch[64/100],d_loss:0.616349,g_loss:2.799875 D real: 0.796379,D fake: 0.170028\n",
      "Epoch[64/100],d_loss:0.701272,g_loss:2.294670 D real: 0.841481,D fake: 0.273299\n",
      "Epoch[65/100],d_loss:0.822381,g_loss:2.687514 D real: 0.723407,D fake: 0.193831\n",
      "Epoch[65/100],d_loss:0.636353,g_loss:2.436041 D real: 0.754722,D fake: 0.158227\n",
      "Epoch[65/100],d_loss:0.769242,g_loss:2.700419 D real: 0.776487,D fake: 0.202834\n",
      "Epoch[65/100],d_loss:0.614570,g_loss:2.395076 D real: 0.872099,D fake: 0.253956\n",
      "Epoch[66/100],d_loss:0.774173,g_loss:2.385806 D real: 0.870681,D fake: 0.355668\n",
      "Epoch[66/100],d_loss:0.587551,g_loss:2.632082 D real: 0.799045,D fake: 0.176380\n",
      "Epoch[66/100],d_loss:0.804842,g_loss:2.128646 D real: 0.843966,D fake: 0.324055\n",
      "Epoch[66/100],d_loss:0.733534,g_loss:3.115807 D real: 0.756803,D fake: 0.195346\n",
      "Epoch[67/100],d_loss:0.554458,g_loss:3.155728 D real: 0.828094,D fake: 0.190063\n",
      "Epoch[67/100],d_loss:0.355104,g_loss:3.267910 D real: 0.910632,D fake: 0.176151\n",
      "Epoch[67/100],d_loss:0.686831,g_loss:2.275093 D real: 0.816008,D fake: 0.266299\n",
      "Epoch[67/100],d_loss:0.521468,g_loss:2.754404 D real: 0.877353,D fake: 0.210040\n",
      "Epoch[68/100],d_loss:0.806333,g_loss:2.614480 D real: 0.749284,D fake: 0.193357\n",
      "Epoch[68/100],d_loss:0.629011,g_loss:2.242974 D real: 0.814644,D fake: 0.225101\n",
      "Epoch[68/100],d_loss:0.677664,g_loss:2.078225 D real: 0.779070,D fake: 0.217125\n",
      "Epoch[68/100],d_loss:0.606706,g_loss:2.145426 D real: 0.776160,D fake: 0.162275\n",
      "Epoch[69/100],d_loss:0.812512,g_loss:2.323710 D real: 0.729276,D fake: 0.211002\n",
      "Epoch[69/100],d_loss:0.653829,g_loss:2.416631 D real: 0.748698,D fake: 0.163715\n",
      "Epoch[69/100],d_loss:0.827821,g_loss:2.023738 D real: 0.739297,D fake: 0.229643\n",
      "Epoch[69/100],d_loss:0.770639,g_loss:2.276300 D real: 0.709206,D fake: 0.174485\n",
      "Epoch[70/100],d_loss:0.680064,g_loss:1.848525 D real: 0.820041,D fake: 0.237127\n",
      "Epoch[70/100],d_loss:0.629464,g_loss:2.322755 D real: 0.793369,D fake: 0.188394\n",
      "Epoch[70/100],d_loss:0.887158,g_loss:2.214592 D real: 0.712189,D fake: 0.243588\n",
      "Epoch[70/100],d_loss:0.879930,g_loss:2.378703 D real: 0.680122,D fake: 0.200646\n",
      "Epoch[71/100],d_loss:0.546751,g_loss:2.663798 D real: 0.838960,D fake: 0.202860\n",
      "Epoch[71/100],d_loss:0.729400,g_loss:2.247572 D real: 0.804491,D fake: 0.235316\n",
      "Epoch[71/100],d_loss:0.688906,g_loss:2.078876 D real: 0.791597,D fake: 0.225541\n",
      "Epoch[71/100],d_loss:0.726124,g_loss:1.627480 D real: 0.809836,D fake: 0.297479\n",
      "Epoch[72/100],d_loss:0.685509,g_loss:2.120384 D real: 0.790167,D fake: 0.235274\n",
      "Epoch[72/100],d_loss:0.866026,g_loss:1.896297 D real: 0.828677,D fake: 0.329503\n",
      "Epoch[72/100],d_loss:0.726558,g_loss:1.796232 D real: 0.765877,D fake: 0.225709\n",
      "Epoch[72/100],d_loss:0.567443,g_loss:2.607229 D real: 0.818721,D fake: 0.197502\n",
      "Epoch[73/100],d_loss:0.779635,g_loss:1.568666 D real: 0.745858,D fake: 0.204321\n",
      "Epoch[73/100],d_loss:0.558122,g_loss:2.421319 D real: 0.825407,D fake: 0.194557\n",
      "Epoch[73/100],d_loss:0.662521,g_loss:2.218897 D real: 0.787762,D fake: 0.224485\n",
      "Epoch[73/100],d_loss:0.698842,g_loss:1.971284 D real: 0.759769,D fake: 0.199524\n",
      "Epoch[74/100],d_loss:0.670776,g_loss:2.288870 D real: 0.776152,D fake: 0.201421\n",
      "Epoch[74/100],d_loss:0.637991,g_loss:2.114757 D real: 0.832959,D fake: 0.228938\n",
      "Epoch[74/100],d_loss:1.126604,g_loss:1.413882 D real: 0.593648,D fake: 0.220912\n",
      "Epoch[74/100],d_loss:0.771539,g_loss:1.509234 D real: 0.821746,D fake: 0.325422\n",
      "Epoch[75/100],d_loss:1.031966,g_loss:2.213781 D real: 0.628624,D fake: 0.167356\n",
      "Epoch[75/100],d_loss:0.756249,g_loss:2.098013 D real: 0.811386,D fake: 0.310772\n",
      "Epoch[75/100],d_loss:0.762249,g_loss:2.127254 D real: 0.748058,D fake: 0.205764\n",
      "Epoch[75/100],d_loss:0.864253,g_loss:2.170318 D real: 0.715271,D fake: 0.229493\n",
      "Epoch[76/100],d_loss:0.712296,g_loss:2.454526 D real: 0.769330,D fake: 0.251474\n",
      "Epoch[76/100],d_loss:0.839685,g_loss:1.845453 D real: 0.804993,D fake: 0.315137\n",
      "Epoch[76/100],d_loss:0.653659,g_loss:2.599532 D real: 0.803081,D fake: 0.231387\n",
      "Epoch[76/100],d_loss:0.692150,g_loss:2.801841 D real: 0.780523,D fake: 0.204418\n",
      "Epoch[77/100],d_loss:0.623115,g_loss:1.956778 D real: 0.791783,D fake: 0.199605\n",
      "Epoch[77/100],d_loss:0.682197,g_loss:2.051067 D real: 0.741417,D fake: 0.148727\n",
      "Epoch[77/100],d_loss:0.693688,g_loss:2.566556 D real: 0.752786,D fake: 0.206347\n",
      "Epoch[77/100],d_loss:0.700665,g_loss:1.907600 D real: 0.796211,D fake: 0.238508\n",
      "Epoch[78/100],d_loss:0.620295,g_loss:2.132871 D real: 0.800599,D fake: 0.204122\n",
      "Epoch[78/100],d_loss:0.701273,g_loss:2.810084 D real: 0.740598,D fake: 0.173268\n",
      "Epoch[78/100],d_loss:0.677109,g_loss:2.108697 D real: 0.784279,D fake: 0.201164\n",
      "Epoch[78/100],d_loss:0.618829,g_loss:2.905690 D real: 0.746372,D fake: 0.153980\n",
      "Epoch[79/100],d_loss:0.758713,g_loss:2.689991 D real: 0.778867,D fake: 0.221245\n",
      "Epoch[79/100],d_loss:0.669735,g_loss:2.317200 D real: 0.745473,D fake: 0.160752\n",
      "Epoch[79/100],d_loss:0.651537,g_loss:2.307874 D real: 0.786127,D fake: 0.209761\n",
      "Epoch[79/100],d_loss:0.668926,g_loss:2.387290 D real: 0.781417,D fake: 0.220999\n",
      "Epoch[80/100],d_loss:0.693911,g_loss:2.041091 D real: 0.760618,D fake: 0.192915\n",
      "Epoch[80/100],d_loss:0.743225,g_loss:2.340357 D real: 0.786780,D fake: 0.243037\n",
      "Epoch[80/100],d_loss:0.884500,g_loss:2.687029 D real: 0.737578,D fake: 0.271643\n",
      "Epoch[80/100],d_loss:0.608050,g_loss:2.308473 D real: 0.813091,D fake: 0.222149\n",
      "Epoch[81/100],d_loss:0.497382,g_loss:2.180626 D real: 0.872242,D fake: 0.234631\n",
      "Epoch[81/100],d_loss:0.815761,g_loss:2.309679 D real: 0.737103,D fake: 0.250258\n",
      "Epoch[81/100],d_loss:0.600377,g_loss:2.843307 D real: 0.793582,D fake: 0.188341\n",
      "Epoch[81/100],d_loss:0.973562,g_loss:1.946415 D real: 0.752888,D fake: 0.347710\n",
      "Epoch[82/100],d_loss:0.901655,g_loss:1.638559 D real: 0.752584,D fake: 0.325575\n",
      "Epoch[82/100],d_loss:0.659247,g_loss:1.595638 D real: 0.861315,D fake: 0.293873\n",
      "Epoch[82/100],d_loss:0.620935,g_loss:1.661001 D real: 0.820210,D fake: 0.238004\n",
      "Epoch[82/100],d_loss:0.768072,g_loss:2.000311 D real: 0.782908,D fake: 0.276417\n",
      "Epoch[83/100],d_loss:0.628149,g_loss:2.000419 D real: 0.823455,D fake: 0.241781\n",
      "Epoch[83/100],d_loss:0.798295,g_loss:1.530186 D real: 0.793292,D fake: 0.292782\n",
      "Epoch[83/100],d_loss:0.681122,g_loss:1.931580 D real: 0.781187,D fake: 0.225393\n",
      "Epoch[83/100],d_loss:0.597134,g_loss:2.482464 D real: 0.761736,D fake: 0.167175\n",
      "Epoch[84/100],d_loss:0.884792,g_loss:1.959549 D real: 0.815497,D fake: 0.327289\n",
      "Epoch[84/100],d_loss:0.646684,g_loss:2.383609 D real: 0.790070,D fake: 0.231660\n",
      "Epoch[84/100],d_loss:0.821750,g_loss:2.043198 D real: 0.712309,D fake: 0.201702\n",
      "Epoch[84/100],d_loss:0.773939,g_loss:2.138096 D real: 0.806317,D fake: 0.304959\n",
      "Epoch[85/100],d_loss:0.709871,g_loss:2.137003 D real: 0.750128,D fake: 0.213461\n",
      "Epoch[85/100],d_loss:0.972242,g_loss:1.695657 D real: 0.734361,D fake: 0.298632\n",
      "Epoch[85/100],d_loss:0.856361,g_loss:2.031284 D real: 0.743145,D fake: 0.267479\n",
      "Epoch[85/100],d_loss:0.727251,g_loss:1.755557 D real: 0.777333,D fake: 0.278690\n",
      "Epoch[86/100],d_loss:0.753448,g_loss:1.963332 D real: 0.747356,D fake: 0.221319\n",
      "Epoch[86/100],d_loss:0.829390,g_loss:1.872636 D real: 0.752823,D fake: 0.232522\n",
      "Epoch[86/100],d_loss:1.012010,g_loss:1.264555 D real: 0.690295,D fake: 0.277917\n",
      "Epoch[86/100],d_loss:0.771253,g_loss:1.878848 D real: 0.746930,D fake: 0.251853\n",
      "Epoch[87/100],d_loss:0.875543,g_loss:2.155943 D real: 0.709004,D fake: 0.246862\n",
      "Epoch[87/100],d_loss:0.957305,g_loss:1.546072 D real: 0.636288,D fake: 0.181582\n",
      "Epoch[87/100],d_loss:0.709596,g_loss:2.236231 D real: 0.775301,D fake: 0.247854\n",
      "Epoch[87/100],d_loss:0.899234,g_loss:1.907134 D real: 0.719814,D fake: 0.257380\n",
      "Epoch[88/100],d_loss:0.739726,g_loss:2.203184 D real: 0.832258,D fake: 0.301651\n",
      "Epoch[88/100],d_loss:0.938526,g_loss:1.900795 D real: 0.684398,D fake: 0.218266\n",
      "Epoch[88/100],d_loss:0.846151,g_loss:2.020848 D real: 0.687212,D fake: 0.216907\n",
      "Epoch[88/100],d_loss:0.714481,g_loss:1.913167 D real: 0.793978,D fake: 0.242377\n",
      "Epoch[89/100],d_loss:0.765471,g_loss:2.162727 D real: 0.792606,D fake: 0.277476\n",
      "Epoch[89/100],d_loss:0.799899,g_loss:1.943872 D real: 0.691117,D fake: 0.188256\n",
      "Epoch[89/100],d_loss:0.736079,g_loss:1.908823 D real: 0.819506,D fake: 0.280366\n",
      "Epoch[89/100],d_loss:0.700186,g_loss:1.874035 D real: 0.750961,D fake: 0.187265\n",
      "Epoch[90/100],d_loss:0.780718,g_loss:2.022411 D real: 0.727987,D fake: 0.215672\n",
      "Epoch[90/100],d_loss:0.705550,g_loss:2.290140 D real: 0.764297,D fake: 0.218070\n",
      "Epoch[90/100],d_loss:0.961935,g_loss:1.945020 D real: 0.739532,D fake: 0.318997\n",
      "Epoch[90/100],d_loss:0.723567,g_loss:1.763768 D real: 0.766370,D fake: 0.250638\n",
      "Epoch[91/100],d_loss:0.711367,g_loss:2.147455 D real: 0.792521,D fake: 0.262686\n",
      "Epoch[91/100],d_loss:0.692990,g_loss:1.911255 D real: 0.738287,D fake: 0.187385\n",
      "Epoch[91/100],d_loss:0.782907,g_loss:2.492385 D real: 0.879135,D fake: 0.349086\n",
      "Epoch[91/100],d_loss:0.884701,g_loss:2.652889 D real: 0.680083,D fake: 0.194802\n",
      "Epoch[92/100],d_loss:0.947786,g_loss:1.570877 D real: 0.770801,D fake: 0.340209\n",
      "Epoch[92/100],d_loss:0.591568,g_loss:2.521133 D real: 0.807308,D fake: 0.219817\n",
      "Epoch[92/100],d_loss:0.899092,g_loss:1.455755 D real: 0.786697,D fake: 0.313829\n",
      "Epoch[92/100],d_loss:0.734506,g_loss:2.180454 D real: 0.730860,D fake: 0.169195\n",
      "Epoch[93/100],d_loss:0.848366,g_loss:1.630134 D real: 0.744816,D fake: 0.294288\n",
      "Epoch[93/100],d_loss:1.051400,g_loss:1.742823 D real: 0.743045,D fake: 0.383252\n",
      "Epoch[93/100],d_loss:0.966058,g_loss:1.993095 D real: 0.651365,D fake: 0.206793\n",
      "Epoch[93/100],d_loss:0.952793,g_loss:2.398373 D real: 0.617657,D fake: 0.172295\n",
      "Epoch[94/100],d_loss:0.640413,g_loss:2.532140 D real: 0.766286,D fake: 0.206244\n",
      "Epoch[94/100],d_loss:0.841194,g_loss:1.904371 D real: 0.706361,D fake: 0.250071\n",
      "Epoch[94/100],d_loss:0.760922,g_loss:1.649479 D real: 0.751143,D fake: 0.247829\n",
      "Epoch[94/100],d_loss:0.916748,g_loss:1.815687 D real: 0.710797,D fake: 0.260879\n",
      "Epoch[95/100],d_loss:0.977540,g_loss:1.901480 D real: 0.629215,D fake: 0.212038\n",
      "Epoch[95/100],d_loss:0.740258,g_loss:1.906496 D real: 0.698043,D fake: 0.160250\n",
      "Epoch[95/100],d_loss:0.844317,g_loss:1.758667 D real: 0.678281,D fake: 0.234487\n",
      "Epoch[95/100],d_loss:0.826753,g_loss:2.080122 D real: 0.685202,D fake: 0.190007\n",
      "Epoch[96/100],d_loss:0.730656,g_loss:1.932849 D real: 0.748074,D fake: 0.230434\n",
      "Epoch[96/100],d_loss:0.940687,g_loss:1.788474 D real: 0.778940,D fake: 0.356579\n",
      "Epoch[96/100],d_loss:0.806003,g_loss:1.575538 D real: 0.694205,D fake: 0.242004\n",
      "Epoch[96/100],d_loss:0.709164,g_loss:1.873795 D real: 0.823604,D fake: 0.316830\n",
      "Epoch[97/100],d_loss:1.032661,g_loss:1.834092 D real: 0.802377,D fake: 0.422147\n",
      "Epoch[97/100],d_loss:0.818993,g_loss:2.075896 D real: 0.745285,D fake: 0.253951\n",
      "Epoch[97/100],d_loss:0.836727,g_loss:2.106308 D real: 0.680445,D fake: 0.197686\n",
      "Epoch[97/100],d_loss:0.821550,g_loss:1.937528 D real: 0.711732,D fake: 0.224591\n",
      "Epoch[98/100],d_loss:0.862168,g_loss:1.893932 D real: 0.810292,D fake: 0.340985\n",
      "Epoch[98/100],d_loss:0.980909,g_loss:1.961661 D real: 0.714211,D fake: 0.314094\n",
      "Epoch[98/100],d_loss:1.150273,g_loss:1.093906 D real: 0.660910,D fake: 0.297938\n",
      "Epoch[98/100],d_loss:0.765873,g_loss:2.369590 D real: 0.746721,D fake: 0.238142\n",
      "Epoch[99/100],d_loss:0.483408,g_loss:2.542790 D real: 0.831060,D fake: 0.185311\n",
      "Epoch[99/100],d_loss:0.755275,g_loss:1.994694 D real: 0.746675,D fake: 0.200782\n",
      "Epoch[99/100],d_loss:0.660048,g_loss:1.891620 D real: 0.811927,D fake: 0.271286\n",
      "Epoch[99/100],d_loss:0.868691,g_loss:1.581793 D real: 0.758199,D fake: 0.316343\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a30e478926492f8c23d1065458ee8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>discriminator_loss</td><td>▁▄▄█▄▄▂▃▄▄▃▂▂▂▂▃▅▃▃▄▃▃▄▄▃▅▄▄▃▄▅▄▄▅▄▃▅▄▅▃</td></tr><tr><td>generator_loss</td><td>█▆▂▅▁▅▅▆▅▆▄▇▆▅▅▅▅▅▄▆▄▄▄▃▅▂▃▃▂▃▃▂▃▂▂▂▁▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>discriminator_loss</td><td>0.59048</td></tr><tr><td>generator_loss</td><td>1.94841</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jolly-valley-1</strong> at: <a href='https://wandb.ai/sjtuzjp/gan-mnist/runs/1p7gpje3' target=\"_blank\">https://wandb.ai/sjtuzjp/gan-mnist/runs/1p7gpje3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230307_105233-1p7gpje3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 首先需要定义loss的度量方式  （二分类的交叉熵）\n",
    "# 其次定义 优化函数,优化函数的学习率为0.0003\n",
    "criterion = nn.BCELoss()  # 是单目标二分类交叉熵函数\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)\n",
    "\n",
    "# ##########################进入训练##判别器的判断过程#####################\n",
    "for epoch in range(num_epoch):  # 进行多个epoch的训练\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        num_img = img.size(0)\n",
    "        # view()函数作用是将一个多行的Tensor,拼接成一行\n",
    "        # 第一个参数是要拼接的tensor,第二个参数是-1\n",
    "        # =============================训练判别器==================\n",
    "        img = img.view(num_img, -1)  # 将图片展开为28*28=784\n",
    "        real_img = Variable(img).cuda()  # 将tensor变成Variable放入计算图中\n",
    "        real_label = Variable(torch.ones(num_img)).cuda()  # 定义真实的图片label为1\n",
    "        fake_label = Variable(torch.zeros(num_img)).cuda()  # 定义假的图片的label为0\n",
    "\n",
    "        # ########判别器训练train#####################\n",
    "        # 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "        # 计算真实图片的损失\n",
    "        real_out = D(real_img)  # 将真实图片放入判别器中\n",
    "        real_out = real_out.squeeze()  # (128,1) -> (128,)\n",
    "        d_loss_real = criterion(real_out, real_label)  # 得到真实图片的loss\n",
    "        real_scores = real_out  # 得到真实图片的判别值，输出的值越接近1越好\n",
    "        # 计算假的图片的损失\n",
    "        z = Variable(torch.randn(num_img, z_dimension)).cuda()  # 随机生成一些噪声\n",
    "        fake_img = G(\n",
    "            z).detach()  # 随机噪声放入生成网络中，生成一张假的图片。 # 避免梯度传到G，因为G不用更新, detach分离\n",
    "        fake_out = D(fake_img)  # 判别器判断假的图片，\n",
    "        fake_out = fake_out.squeeze()  # (128,1) -> (128,)\n",
    "        d_loss_fake = criterion(fake_out, fake_label)  # 得到假的图片的loss\n",
    "        fake_scores = fake_out  # 得到假图片的判别值，对于判别器来说，假图片的损失越接近0越好\n",
    "        # 损失函数和优化\n",
    "        d_loss = d_loss_real + d_loss_fake  # 损失包括判真损失和判假损失\n",
    "        d_optimizer.zero_grad()  # 在反向传播之前，先将梯度归0\n",
    "        d_loss.backward()  # 将误差反向传播\n",
    "        d_optimizer.step()  # 更新参数\n",
    "\n",
    "        # ==================训练生成器============================\n",
    "        # ###############################生成网络的训练###############################\n",
    "        # 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "        # 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "        # 反向传播更新的参数是生成网络里面的参数，\n",
    "        # 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的\n",
    "        # 这样就达到了对抗的目的\n",
    "        # 计算假的图片的损失\n",
    "        z = Variable(torch.randn(num_img, z_dimension)).cuda()  # 得到随机噪声\n",
    "        fake_img = G(z)  # 随机噪声输入到生成器中，得到一副假的图片\n",
    "        output = D(fake_img)  # 经过判别器得到的结果\n",
    "        output = output.squeeze()\n",
    "        g_loss = criterion(output, real_label)  # 得到的假的图片与真实的图片的label的loss\n",
    "        # bp and optimize\n",
    "        g_optimizer.zero_grad()  # 梯度归0\n",
    "        g_loss.backward()  # 进行反向传播\n",
    "        g_optimizer.step()  # .step()一般用在反向传播后面,用于更新生成网络的参数\n",
    "\n",
    "        # 打印中间的损失\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch[{}/{}],d_loss:{:.6f},g_loss:{:.6f} '\n",
    "                  'D real: {:.6f},D fake: {:.6f}'.format(\n",
    "                      epoch,\n",
    "                      num_epoch,\n",
    "                      d_loss.data.item(),\n",
    "                      g_loss.data.item(),\n",
    "                      real_scores.data.mean(),\n",
    "                      fake_scores.data.mean()  # 打印的是真实图片的损失均值\n",
    "                  ))\n",
    "        if epoch == 0:\n",
    "            real_images = to_img(real_img.cpu().data)\n",
    "            save_image(real_images, './img/real_images.png')\n",
    "    wandb.log({\"generator_loss\": g_loss, \"discriminator_loss\": d_loss})\n",
    "    fake_images = to_img(fake_img.cuda().data)\n",
    "    save_image(fake_images, './img/fake_images-{}.png'.format(epoch + 1))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(G.state_dict(), './generator.pth')\n",
    "torch.save(D.state_dict(), './discriminator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3090",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e578467fa5c12cffc301a3bc3421e1911b67151edde074c28fc0dd02d3ed613c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
